---
output: pdf_document
---
```{r setup, echo=FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
suppressMessages(expr = {
  if ("xfun" %in% row.names(installed.packages()) == FALSE) {
    install.packages("xfun")
  }

  display_markdown <<- knitr::asis_output
  display_html <<- knitr::asis_output

  xfun::pkg_attach(
    c(
      "tidyverse",
      "polspline",
      "patchwork",
      "magrittr",
      "bayesplay",
      "knitr",
      "broom",
      "bayesplay"
    ),
    install = TRUE
  )
})

table_format <- "html"
```
# Final thoughts: Uncertainty and belief
<a href="data:text/x-markdown;base64,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" download="08-final-thoughts.Rmd"><img src="https://img.shields.io/badge/.Rmd-Download-blue"></a>
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ljcolling/bayes2022/blob/main/_notebooks/08-final-thoughts.ipynb)

Before we finish I just wanted to leave you with some final thoughts about
uncertainty. Uncertainty is everywhere in science, but as scientists we are
often reluctant to admit it. Maybe this is partly due to a fear of how
uncertainty will be exploited, for example, in the case of scepticism about
human induced climate change or the efficacy of vaccines. However, there's no
getting away from the reality that the things we believe for certain to be true
today may turn out to be, at best, incomplete pictures of how the world works
and, at worst, wholly false.

However, rather than shying away from uncertainty, I think it is better to
embrace it, and to be upfront about it. In this section, I wanted to briefly
touch on two aspects of uncertainty. The first, has to do with uncertainty
in our statistical models, specifically the priors that we use in our
analyses. And the second has to do with evidence and belief. Given some
evidence from our statistical analysis, how do we know what we should
believe.

## Uncertainty about priors

In the examples in the preceding sections, we often set one prior for our
alternative hypothesis. For example, we might have used a specific Cauchy
distribution---that is, a Cauchy distribution centred at 0, with a specific
scale factor. But this decision is not the only decision we could have
made. We could've chosen a different scale factor. Maybe we're not sure if
we're expecting large effect sizes or medium effect sizes so we're unsure
about exactly which scale factor we should pick. We just don't know what
the **one true prior** is. This probably is made worse by the fact that
choosing a different prior might lead to a different result. We can see
just such a case in the example below.

In the following example, we can see two analyses of the same data. First
the analysis is performed with a Cauchy prior with a scale factor of 2.

```{r}


#chunk_1

```

The results show **anecdotal** evidence in favour of the alternative
hypothesis.

Next, the analysis is performed with a Cauchy prior with a scale factor of
0.707.

```{r}
#| echo = TRUE, include = TRUE

data_model <- likelihood(family = "noncentral_d", d = 0.55, n = 24)
alt_prior <- prior(family = "cauchy", location = 0, scale = .707)
null_prior <- prior(family = "point", point = 0)
bf <- integral(data_model * alt_prior) / integral(data_model * null_prior)
summary(bf)

```

The results now show **moderate** evidence in favour of the alternative
hypothesis. So which is it?

The solution here is to not think in absolutes. If we're unsure of the
scale, then rather than pretending that we're certain, we can perform the
analysis on our best guess, and then additionally perform the analysis on
the reasonable upper and lower bounds of where we think the scale factor
lies.

Alternatively, we can make use of the idea of a **robustness region**. The
idea of the robustness region is that we perform the analysis on our best
guess of the prior. And that we then find the range of scale factors that
produce a result that leads to the same conclusion. For example, in the
code below, an analysis is performed with a specific scale factor.

```{r}
#| echo = TRUE, include = TRUE

data_model <- likelihood(
  family = "normal",
  mean = -0.05,
  sd = 0.11
)

alt_prior <- prior(
  family = "normal",
  mean = 0,
  sd = 0.58, range = c(0, Inf)
)

null_prior <- prior(family = "point", point = 0)

m1 <- data_model * alt_prior
m0 <- data_model * null_prior

bf <- integral(m0) / integral(m1)

summary(bf)

```

The results show **moderate evidence** in favour of the null hypothesis.
Following this, the scale factor is varied across a wide range, and the
upper and lower bounds of the range of the scale factor that lead to the
same conclusion---that is, **moderate evidence** or stronger in favour of
the null hypothesis, or a Bayes factor of greater than 3---are determined.

```{r}
#| echo = TRUE, include = TRUE
calc_bf <- function(prior_scale) {
  data_model <- likelihood(
    family = "normal",
    mean = -0.05,
    sd = 0.11
  )

  alt_prior <- prior(
    family = "normal",
    mean = 0,
    sd = prior_scale, range = c(0, Inf)
  )

  null_prior <- prior(family = "point", point = 0)

  m1 <- data_model * alt_prior
  m0 <- data_model * null_prior

  integral(m0) / integral(m1)
}

bf_values <- map_df(seq(0.01, 10, .01), function(x) {
  tibble(
    scale_factor = x,
    bf = calc_bf(x)
  )
})

min_max_bounds <- bf_values %>%
  filter(bf > 3) %>%
  filter(bf == min(bf) | bf == max(bf)) %>%
  pull(scale_factor)

glue::glue(
  "The robustness region has a lower bound at",
  " {min_max_bounds[[1]]} and an upper bound at greater than",
  " greater than {min_max_bounds[[2]]}"
) %>%
  display_markdown()

```

These upper and lower bounds can now be reported along with the Bayes factor
value.

In your actual research, reporting robustness regions can be incredibly
valuable, because we should own up to uncertainty rather than hiding it
behind a facade of certainty.

## Beliefs are updated by evidence

In the preceding sections, I mainly just reported the numeric value for
the Bayes factor rather than any verbal description. This was intentional.
Bayes factors are a continuous measure of evidence and the use of verbal
labels encourages thinking in terms of thresholds. For example, we might
conclude that we have an effect only if we find strong evidence but not
moderate evidence. However, these verbal labels should not be treated as
thresholds. Only as rules of thumb. Making conclusions about whether we've
found something or not is going to depend not just on statistical
reasoning but, more importantly, scientific reasoning (e.g., see [Colling
& Sz≈±cs,
2020](https://link.springer.com/content/pdf/10.1007/s13164-018-0421-4.pdf)).

Moreover, evidence and belief are distinct things. Our beliefs should be
based on evidence (if we want to be rational) but evidence is not consumed
in a vacuum. We all have beliefs about how the world works. Ideally, these
should be based on evidence. But when we encounter new evidence that
evidence is evaluated in light of our prior beliefs and those beliefs are
updated.

If all this seems rather abstract, here is an example that is analogous to
a famous published experiment by [Bem
(2011)](https://doi.apa.org/doiLanding?doi=10.1037%2Fa0021524). In this
experiment, we're going to ask somebody to answer a series of True/False
questions, and then we're going to evaluate whether they performed at
chance or not. But there's a twist. We're just going to ask them for their
answers, but we're not going to tell them what the questions are. What we
want to test is whether our participant can **read our minds** to figure
out what the questions are before answering them. If they can, then we
expect them to perform better than chance.

Here are some simulated data:

```{r}
#| include = TRUE, echo = TRUE

set.seed(32)
correct <- purrr::rbernoulli(30)
sum(correct)
length(correct)

paste0(correct, collapse = ", ")  %>%
  display_markdown()

```

We can model this with a binomial likelihood:

```{r}
#| include = TRUE, echo = TRUE

data_model <- likelihood(
  family = "binomial",
  successes = 22,
  trials = 30
)

plot(data_model) +
  theme_minimal(14)

```

And for our priors, we'll use a point null at 0.5, and a Beta(18,5)
distribution for our alternative.

```{r}
#| include = TRUE, echo = TRUE

alt_prior <- prior(
  family = "beta",
  alpha = 18,
  beta = 5
)


null_prior <- prior(
  family = "point",
  point = 0.5
)

alt_plot <- plot(alt_prior) +
  theme_minimal(14) +
  labs(subtitle = "Alternative")

null_plot <- plot(null_prior) +
  theme_minimal(14) +
  labs(subtitle = "Null")

alt_plot | null_plot

```

Computing the Bayes factor, we get the following:

```{r}
#| include = TRUE, echo = TRUE

m1 <- data_model * alt_prior
m0 <- data_model * null_prior

bf10 <- integral(m1) / integral(m0)

summary(bf10)

```

So what now do we make of this? The evidence supports the model that
represented our hypothesis that **this person can read minds**! Do we now
conclude that this is true?

I would say, "not so fast!" But why? Before we can decide what we believe now,
after seeing the evidence, we have to know what we believed before the
evidence. Before seeing this evidence, it seems reasonable to believe that it
is very unlikely that this person can actually read minds. To believe otherwise
would require discarding huge amounts of knowledge we have about how the world
works. Work from many different scientific fields gives us a picture of the
world where such mind reading abilities seem very improbable.

We can formalise this and assign a probability to it. We might say there's
only a 0.2% probability that our H1 (mind reading) is true. And that
there's a 99.8% probability that our H0 (no mind reading) is true. We can
now take our Bayes factor, together with our prior beliefs, to decide what
we should believe now the we've seen the evidence. 

For example, for a given prior belief in $M_0$ and $M_1$, denoted $p(M_0)$
and $p(M_1)$, and a given Bayes factor for $M_1$ over $M_0$, denoted
$BF_{10}$, our posterior beliefs, denoted $p(M_1|D)$ can be calculated as
follows:

$$p(M_1|D) = \frac{p(M_0)}{\mathrm{BF_{10}}\cdot{}p(M_1) + p(M_0)}$$

Or, in code:

```{r}
#| include = TRUE, echo = TRUE

prior_1 <- 0.2 / 100
prior_0 <- 1 - prior_1

posterior_0 <- prior_0 / (bf10 * prior_1 + prior_0)
posterior_1 <- 1 - posterior_0

glue::glue("
           Before seeing the data there was a {prior_1} probability
that the alternative hypothesis was true, and a {prior_0} probability
that the null hypothesis was true.


Our analysis said that the data were {round(bf10,2)} times more
likely under the alternative hypothesis than the null hypothesis.

Taking this evidence into account, we now believe there's a 
{round(posterior_1,3)} probability that our alternative hypothesis
is true. ") %>%
  display_markdown()
```

Now of course we have new beliefs that could serve as our priors belief when we
conduct another experiment. We'd use the evidence from that experiment to
update our beliefs again.

Bayesian methods allow us to make sure we're always rationally updating our
beliefs in light of new evidence in a mathematically precise way. But more
informally, this is something we do every day. The more unbelievable the claim,
the stronger the evidence we should need before we believe it. Statistical
results always need to be understood in the wider scientific context. They're
not magically arbiters of truth. It's disappointing that the journal
editors and reviewer responsible for publishing the [Bem
(2011)](https://doi.apa.org/doiLanding?doi=10.1037%2Fa0021524) paper
forgot this.
