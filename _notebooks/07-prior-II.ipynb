{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbe179a",
   "metadata": {
    "lines_to_next_cell": 0,
    "message": false,
    "name": "setup",
    "tags": [
     "remove_input"
    ],
    "warning": false
   },
   "outputs": [],
   "source": [
    "knitr::opts_chunk$set(echo = FALSE)\n",
    "suppressMessages(expr =  {\n",
    "  if (\"xfun\" %in% row.names(installed.packages()) == FALSE) {\n",
    "    install.packages(\"xfun\")\n",
    "  }\n",
    "\n",
    "display_markdown <- \\(x) IRdisplay::display_markdown(as.character(x))\n",
    "display_html <- \\(x) IRdisplay::display_html(as.character(x))\n",
    "\n",
    "xfun::pkg_attach(\n",
    "    c(\"tidyverse\",\n",
    "      \"polspline\",\n",
    "      \"patchwork\",\n",
    "      \"magrittr\",\n",
    "      \"bayesplay\",\n",
    "      \"knitr\",\n",
    "      \"broom\",\n",
    "      \"bayesplay\"),\n",
    "      install = TRUE)\n",
    "\n",
    "})\n",
    "\n",
    "table_format <- \"html\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5b555",
   "metadata": {},
   "source": [
    "# Choosing priors: Part II\n",
    "\n",
    "Although the method of using default priors is easy to use some have\n",
    "questioned whether it really makes sense to talk of **default**\n",
    "hypotheses. The real power of Bayes factors comes from *directly testing\n",
    "theories*, and as [Dienes\n",
    "(2019)](https://doi.org/10.1177/2515245919876960) points out, \"there is no\n",
    "such thing as a default theory, so there cannot be a default\" alternative\n",
    "hypothesis. Dienes instead recommends formulating priors for our specific\n",
    "situation at hand. That is, formulating priors that actually match our\n",
    "scientific theories about how the world works.\n",
    "\n",
    "The second set of priors that we developed for the coin flip examples\n",
    "represents a case of doing this. Instead of saying that our alternative\n",
    "hypothesis should represent each outcome as being equally likely we instead\n",
    "came up with a theory of how biased coins are likely to behave. In fact, we\n",
    "came up with a few theories. One theory, for example, said that biased coins\n",
    "would show heads more often. And another theory said that biased coins would\n",
    "behave similarly to fair coins; however, they would show heads or tails\n",
    "slightly less often than would be expected from a fair coin. We were able to\n",
    "come up with priors that directly represented these theories and we were able\n",
    "to compute Bayes factors comparing these theories with our fair coin theory\n",
    "(that the bias is exactly 0.5).\n",
    "\n",
    "Of course using these kinds of priors is far more difficult than using\n",
    "default priors because it forces us to think about what our scientific\n",
    "theories predict. However, as scientists, we probably should be thinking\n",
    "about what our theories predict! But knowing what our scientific theories\n",
    "predict is a very difficult task and, as psychology researchers we are not\n",
    "well trained to think in terms of quantitative predictions. This is\n",
    "likely an artefact of the dominance of *null-hypothesis significance\n",
    "testing* in psychology, because these kinds of statistical procedures\n",
    "encourage thinking in terms of *default* hypotheses (see [Colling & SzÅ±cs,\n",
    "2020](https://link.springer.com/content/pdf/10.1007/s13164-018-0421-4.pdf)).\n",
    "Therefore, adopting Bayesian methods can require a big change in how we\n",
    "think about **theory** in psychology. \n",
    "\n",
    "The aim of this section is not to teach you how to do good **theory**. Instead,\n",
    "the aim is to give you the tools to test theories once you've come up with\n",
    "them. The hope is that once you have the tools, then come up with theories that\n",
    "are testable with those tools. To do this, we'll look at some examples of how\n",
    "to represent and then test theories with Bayes factors. Following this, we'll\n",
    "cover some heuristics for coming up with predictions if we're unsure what\n",
    "our theories predict.\n",
    "\n",
    "## Examples of representing predictions\n",
    "\n",
    "### Representing predictions with a uniform prior\n",
    "\n",
    "The most straightforward way to represent the predictions of a theory is\n",
    "with a uniform prior. A uniform prior essentially represents the idea\n",
    "that, if there is an effect, then it will be some value between a defined\n",
    "minimum and a defined maximum, with all effects being equally probable.\n",
    "\n",
    "Here is an example taken from [Dienes\n",
    "(2014)](https://www.frontiersin.org/articles/10.3389/fpsyg.2014.00781/full).\n",
    "In this example experiment, negative mood was *predicted to reduce\n",
    "learning on a task*. Learning was measured using a two-alternative forced\n",
    "choice measure (chance performance would be 50%). It was found that, in\n",
    "the *neutral mood condition* performance on the task was at 70%. If\n",
    "*negative mood* reduced learning, the population mean of this condition\n",
    "would have to lie somewhere between chance performance (50%) and\n",
    "performance on the neutral condition (70%). Therefore, the difference\n",
    "between conditions would have to be between 0% and 20%. \n",
    "\n",
    "We could represent this as a uniform prior with a minimum of 0 and\n",
    "a maximum of 20. The code below does just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8031cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo = TRUE, include = TRUE\n",
    "\n",
    "mood_theory <- prior(family = \"uniform\", min = 0, max = 20)\n",
    "\n",
    "plot(mood_theory) +\n",
    "  theme_minimal(14) +\n",
    "  labs(x = \"mean difference\", y = \"probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b08e2bb",
   "metadata": {},
   "source": [
    "Now what do the data say? The results report a mean of 65% in the negative\n",
    "mood condition (mean difference of 5%) with a standard error (standard\n",
    "deviation of the mean difference) of 10. We can represent this data with\n",
    "the code below. Following Dienes (2014), we'll use a *normal* likelihood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ca6cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo = TRUE, include = TRUE\n",
    "\n",
    "data_model <- likelihood(family = \"normal\", mean = 5, sd = 10)\n",
    "\n",
    "plot(data_model) +\n",
    "  theme_minimal(14) +\n",
    "  labs(x = \"mean difference\", y = \"likelihood\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc1a7ee",
   "metadata": {},
   "source": [
    "Finally, we'll use a null prior of a point at 0 to represent our *no effect*\n",
    "hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8083aa41",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#| echo = TRUE, include = TRUE\n",
    "\n",
    "null_theory <- prior(family = \"point\", point = 0)\n",
    "\n",
    "plot(null_theory) +\n",
    "  theme_minimal(14) +\n",
    "  labs(x = \"mean difference\", y = \"probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19347b33",
   "metadata": {},
   "source": [
    "With all the parts in place, we can now compute the Bayes factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab78aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo = TRUE, include = TRUE\n",
    "\n",
    "mood_evidence <- integral(data_model * mood_theory)\n",
    "null_evidence <- integral(data_model * null_theory)\n",
    "\n",
    "bf <- mood_evidence / null_evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698a51e7",
   "metadata": {},
   "source": [
    "The resulting Bayes factor is barely different to 1. Therefore, the\n",
    "results don't really give us a strong reason for favouring one theory over\n",
    "the other. \n",
    "\n",
    "Sometimes it is useful to have verbal labels for the strength of evidence.\n",
    "Wagenmakers et al (2017) suggests some verbal labels for strength of\n",
    "evidence, and we can get the verbal label for the computed Bayes factor by\n",
    "using the `summary` function, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198f58ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo = TRUE, include = TRUE\n",
    "\n",
    "summary(bf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6336ee4a",
   "metadata": {},
   "source": [
    "### Representing predictions with a half-normal prior\n",
    "\n",
    "A half normal distribution is another useful way to represent predictions for\n",
    "theories. To come up with predictions for the theory, we'll use the results\n",
    "from an earlier experiment to represent the predictions of the current\n",
    "experiment.\n",
    "\n",
    "Here is an example taken from [Dienes and Mclatchie\n",
    "(2018)](https://link.springer.com/article/10.3758/s13423-017-1266-z). In a\n",
    "study by Williams and Bargh (2008), people were ask to feel a hot or cold\n",
    "therapeutic pack and then choose a treat for themselves or for a friend. Of\n",
    "those participants exposed to a cold pack, 75% chose a treat for themselves\n",
    "where only 45% chose the treat for their friend. We can express this difference\n",
    "as an Odds Ratio (OR). This gives an OR of 3.52, which converted into Log Odds\n",
    "(Log OR) is approximately 1.26. We take the natural log of the odds ratio,\n",
    "because the natural log of the odds ratio is approximately normally\n",
    "distributed, which means that we can model it with a *normal* likelihood.\n",
    "\n",
    "After the original study, Lynott et al (2014) attempted a replication. Before\n",
    "we get to the data that Lynott et al (2014) obtained, let's think about a possible\n",
    "prediction. \n",
    "\n",
    "If the original study reported a true effect, then the replication study\n",
    "should find an effect of roughly the same order of magnitude. Maybe\n",
    "smaller, maybe larger, but not radically different.\n",
    "\n",
    "Furthermore, it's also fair to assume that reported effects are usually larger\n",
    "than the true effect, because larger effects are more likely to get published.\n",
    "So the true effect is more likely to be smaller then the reported effect, and\n",
    "less likely to be larger. How might we represent this idea? One way is with a\n",
    "half normal distribution scaled according to the original finding. That is,\n",
    "with a normal distribution centred at 0, and with a standard deviation of 1.26\n",
    "(that is, the magnitude of the original effect). Furthermore, we'll limit the\n",
    "distribution to be between the values of $0$ and $+\\infty$ (because we have a\n",
    "directional hypothesis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc28c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo = TRUE, include = TRUE\n",
    "\n",
    "theory_model <- prior(\n",
    "  family = \"normal\",\n",
    "  mean = 0,\n",
    "  sd = 1.26,\n",
    "  range = c(0, Inf)\n",
    ")\n",
    "\n",
    "plot(theory_model) +\n",
    "  theme_minimal(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dd0766",
   "metadata": {},
   "source": [
    "By defining the prior in this way, we're saying that ~68% of the plausible\n",
    "effects lie between 0 and 1.26. And ~95% of plausible the effects lie somewhere\n",
    "between 0 and twice the reported original effect (of 1.26). That is, we predict\n",
    "the effect to be somewhere in the same range as the original study, but more\n",
    "probably smaller than the effect originally reported.\n",
    "\n",
    "Now that we have our predictions, we can look at the results of Lynott et al's\n",
    "replication attempt. Their results showed a Log OR of -0.26, with a standard\n",
    "error of 0.14. (Note, that typically, studies don't report the standard error\n",
    "of the Log OR, but rather report the 95% confidence interval of the OR.\n",
    "However, it's possible to compute the standard error of the Log OR from the 95%\n",
    "confidence interval, as shown below). As mentioned above, because Log OR\n",
    "approximately follows a normal distribution, we can model it using the *normal*\n",
    "likelihood, as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0249d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo = TRUE, include = TRUE\n",
    "\n",
    "# For completeness, we'll work out the ln OR and\n",
    "# the standard error from the reported confidence\n",
    "# interval\n",
    "\n",
    "reported_or_ci <- c(0.58, 1.02)\n",
    "\n",
    "log_or_ci <- log(reported_or_ci)\n",
    "log_or <- mean(log_or_ci)\n",
    "log_or_ci_width <- abs(log_or_ci[1] - log_or)\n",
    "log_or_se <- log_or_ci_width / 1.96\n",
    "\n",
    "data_model <- likelihood(\n",
    "  family = \"normal\",\n",
    "  mean = log_or,\n",
    "  sd = log_or_se\n",
    ")\n",
    "\n",
    "plot(data_model) +\n",
    "  theme_minimal(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bc2f40",
   "metadata": {},
   "source": [
    "Finally, for our null hypothesis, we'll just use a point at 0. With all the\n",
    "bit's in place, we can compute the Bayes factor. The code below is generated\n",
    "using the web-app. However, I've just removed the final lines that generate the\n",
    "plots. You can access the web-app's advanced output at the [following\n",
    "link](https://bayesplay.colling.net.nz/advanced?model=%7B%22likelihoodDef%22%3A%7B%22distribution%22%3A%22normal%22%2C%22parameters%22%3A%7B%22mean%22%3A-0.2624623%2C%22sd%22%3A0.1440127%7D%7D%2C%22altpriorDef%22%3A%7B%22distribution%22%3A%22normal%22%2C%22parameters%22%3A%7B%22mean%22%3A0%2C%22sd%22%3A1.26%2C%22min%22%3A0%2C%22max%22%3Anull%7D%7D%2C%22nullpriorDef%22%3A%7B%22distribution%22%3A%22point%22%2C%22parameters%22%3A%7B%22point%22%3A0%7D%7D%7D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da25c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo = TRUE, include = TRUE\n",
    "\n",
    "# define likelihood\n",
    "data_model <- likelihood(family = \"normal\", mean = -0.2624623, sd = 0.1440127)\n",
    "\n",
    "# define alternative prior\n",
    "alt_prior <- prior(family = \"normal\", mean = 0, sd = 1.26, range = c(0, Inf))\n",
    "\n",
    "# define null prior\n",
    "null_prior <- prior(family = \"point\", point = 0)\n",
    "\n",
    "# weight likelihood by prior\n",
    "m1 <- data_model * alt_prior\n",
    "m0 <- data_model * null_prior\n",
    "\n",
    "# take the intergal of each weighted likelihood\n",
    "# and divide them\n",
    "bf <- integral(m1) / integral(m0)\n",
    "\n",
    "# get a verbal description of the Bayes factor\n",
    "summary(bf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58e7794",
   "metadata": {},
   "source": [
    "The results show, strong evidence for the null hypothesis over the\n",
    "alternative hypothesis. The results are $\\frac{1}{0.0411}\\approx24$ times\n",
    "more likely under our null hypothesis than our alternative hypothesis.\n",
    "\n",
    "### Representing predictions with the normal prior\n",
    "\n",
    "In the preceding two examples, we had directional hypotheses. This meant\n",
    "that all our priors were truncated at one end at 0. But sometimes we don't\n",
    "have directional hypotheses. Instead, we might have non-directional\n",
    "hypotheses. If we have non-directional hypotheses then we can use a *full*\n",
    "normal distribution, rather than one that's been limited to be between $0$\n",
    "and $+\\infty$. \n",
    "\n",
    "Furthermore, it is also not necessary to have normal distributions centred\n",
    "at 0. We might use a normal distribution centred at some other value to\n",
    "represent the idea that the effect is roughly with in a certain range but with\n",
    "smaller effects being more probable than larger effects. To see how this works,\n",
    "we'll go through an example in [Dienes\n",
    "(2019)](https://doi.org/10.1177/2515245919876960).\n",
    "\n",
    "Fu et al (2013) were interested in whether there are differences in learning\n",
    "global and local structure between people in China and the UK, and a reaction\n",
    "time task was used to assess this. The results showed that when it came to\n",
    "*global structure*, people in China had superior performance relative to people\n",
    "in the UK. The difference between the two groups was 50 ms (with a standard\n",
    "error of 14 ms). However, for *local structure* learning, the difference was\n",
    "only 15 ms (standard error of 13 ms). \n",
    "\n",
    "Fu et al (2013) wanted to test the theory that people in China simply scored\n",
    "higher on the learning task (irrespective of global or local features)\n",
    "because of higher motivation levels. If motivation levels were the only\n",
    "cause of the differences then the group difference in the global task and the\n",
    "group difference in the local task should be the same.\n",
    "\n",
    "As a result, we could use the results from the global task (mean difference of\n",
    "50 with an standard error of 14) to represent our predictions about the local\n",
    "task. That is, we can use a normal prior with a mean of 50 and a standard\n",
    "deviation of 14, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6ccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo = TRUE, include = TRUE\n",
    "\n",
    "motivation_theory <- prior(\n",
    "  family = \"normal\",\n",
    "  mean = 50,\n",
    "  sd = 14\n",
    ")\n",
    "\n",
    "plot(motivation_theory) +\n",
    "  theme_minimal(14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa775709",
   "metadata": {},
   "source": [
    "And we can use a normal likelihood to represent the data from the local\n",
    "task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada889b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo = TRUE, include = TRUE\n",
    "\n",
    "data_model <- likelihood(\n",
    "  family = \"normal\",\n",
    "  mean = 15,\n",
    "  sd = 13\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf2d29",
   "metadata": {},
   "source": [
    "Once again, we can use a null model with a point at 0.\n",
    "\n",
    "Before we compute the Bayes factor, let's first think about what we're\n",
    "comparing. We have one theory that says: \"People in China score better on\n",
    "a learning task of local features by about the same amount as they\n",
    "outperform people in the UK on a learning task of global features\". And\n",
    "another theory that says: \"People in China and people in the UK score the\n",
    "same on a learning task of local features.\" The Bayes factor that we\n",
    "compute is going to tell us which of **these specific two** hypotheses is\n",
    "better supported by the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c272b71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo = TRUE, include = TRUE\n",
    "\n",
    "motivation_model <- data_model * motivation_theory\n",
    "null_model <- data_model * prior(family = \"point\", 0)\n",
    "\n",
    "motivation_evidence <- integral(motivation_model)\n",
    "null_evidence <- integral(null_model)\n",
    "\n",
    "bf <- motivation_evidence / null_evidence\n",
    "\n",
    "summary(bf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e13506",
   "metadata": {},
   "source": [
    "The results show moderate evidence in favour of the null theory. That is,\n",
    "relative to our specific motivation theory, the null theory is better\n",
    "supported by the data. The Bayes factors are always specific to the exact\n",
    "two hypotheses that we're comparing. \n",
    "\n",
    "If we were to compare different hypotheses then the Bayes factor would be\n",
    "different. Some people find this worrying, but of course it has to be the\n",
    "case! Comparing different hypotheses means asking different questions and\n",
    "therefore we shouldn't be surprised if we get different answers.\n",
    "\n",
    "## How do I know what my theory predicts\n",
    "\n",
    "Again, knowing what our theories predict can be a difficult task. Therefore,\n",
    "[Dienes (2019)](https://doi.org/10.1177/2515245919876960) has come up with some\n",
    "heuristics for thinking about what our theories predict. This paper can be a\n",
    "useful resource for you to turn back to as you come up with your own studies,\n",
    "and develop and test your own theories.\n",
    "\n",
    "A key aspect of the heuristics that Dienes (2019) outlines is thinking about\n",
    "the **maximum possible effect** that can be found between conditions or groups.\n",
    "Once we know this maximum possible effect we can use a *half-normal* prior\n",
    "scaled according to this maximum. Specifically, the standard deviation of the\n",
    "prior is set to half the maximum. This means that ~98% of the plausible effects\n",
    "will lie between 0 and the maximum possible effect. \n",
    "\n",
    "We can go through an example of this heuristic from Dienes (2019). In the\n",
    "example study, by Balzarini, Dharma, Muise, and Kohut (2019), relationship\n",
    "quality for polyamorous and monogamous relationships was measured on a\n",
    "nurturance scale with rating from 1 to 7. It was predicted the in \n",
    "polyamorous relationships, nurturance scores would be higher.\n",
    "\n",
    "The monogamous participants rated their partner's nurturance as 5.85.  While \n",
    "the polyamorous participants rated their partner's nurturance as 5.80. This\n",
    "gave a mean difference of -0.05, and a standard error of 0.11.\n",
    "\n",
    "What is the maximum possible difference between the two groups? The scale runs\n",
    "from 1 to 7, so the maximum possible score the polyamorous group would be 7.\n",
    "If this group had a mean of 7, then the group difference would be 1.15. Using\n",
    "the heuristic, we can use a half-normal prior with a mean of 0 and a \n",
    "standard deviation of $\\frac{1.15}{2}$. Putting this together with a null\n",
    "hypotheses of a point a 0, and our data model with a normal likelihood of a \n",
    "mean of -0.05 (with a standard error of 0.11), we get the following result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c6823f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#| echo = TRUE, include = TRUE\n",
    "\n",
    "# define likelihood\n",
    "data_model <- likelihood(\n",
    "  family = \"normal\",\n",
    "  mean = -0.05,\n",
    "  sd = 0.11\n",
    ")\n",
    "\n",
    "# define alternative prior\n",
    "alt_prior <- prior(\n",
    "  family = \"normal\",\n",
    "  mean = 0,\n",
    "  sd = 0.58, range = c(0, Inf)\n",
    ")\n",
    "\n",
    "# define null prior\n",
    "null_prior <- prior(family = \"point\", point = 0)\n",
    "\n",
    "# weight likelihood by prior\n",
    "m1 <- data_model * alt_prior\n",
    "m0 <- data_model * null_prior\n",
    "\n",
    "# take the intergal of each weighted likelihood\n",
    "# and divide them\n",
    "bf <- integral(m1) / integral(m0)\n",
    "\n",
    "# get a verbal description of the Bayes factor\n",
    "summary(bf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49e7a73",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
