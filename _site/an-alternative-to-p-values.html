<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 An alternative to p values | Bayes rule</title>
  <meta name="description" content="An introduction to Bayesian Statistics" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 An alternative to p values | Bayes rule" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="An introduction to Bayesian Statistics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 An alternative to p values | Bayes rule" />
  
  <meta name="twitter:description" content="An introduction to Bayesian Statistics" />
  

<meta name="author" content="Dr Lincoln Colling" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="criticisms-of-p-values.html"/>
<link rel="next" href="the-bayes-factor.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Stats</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-use-this-book"><i class="fa fa-check"></i>How to use this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#outline"><i class="fa fa-check"></i>Outline</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html"><i class="fa fa-check"></i><b>1</b> Null-hypothesis significance testing</a>
<ul>
<li class="chapter" data-level="1.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#probability"><i class="fa fa-check"></i><b>1.1</b> Probability</a></li>
<li class="chapter" data-level="1.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#probability-and-p-values"><i class="fa fa-check"></i><b>1.2</b> Probability and <em>p</em> values</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#understanding-the-p-through-simulation"><i class="fa fa-check"></i><b>1.2.1</b> Understanding the <em>p</em> through simulation</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#summary"><i class="fa fa-check"></i><b>1.3</b> Summary</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#a-short-note-on-confidence-intervals"><i class="fa fa-check"></i><b>1.3.1</b> A short note on confidence intervals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="criticisms-of-p-values.html"><a href="criticisms-of-p-values.html"><i class="fa fa-check"></i><b>2</b> Criticisms of <em>p</em> values</a>
<ul>
<li class="chapter" data-level="2.1" data-path="criticisms-of-p-values.html"><a href="criticisms-of-p-values.html#same-measurements-from-different-devices"><i class="fa fa-check"></i><b>2.1</b> Same measurements from different devices</a></li>
<li class="chapter" data-level="2.2" data-path="criticisms-of-p-values.html"><a href="criticisms-of-p-values.html#the-universe-of-possible-events"><i class="fa fa-check"></i><b>2.2</b> The universe of possible events</a></li>
<li class="chapter" data-level="2.3" data-path="criticisms-of-p-values.html"><a href="criticisms-of-p-values.html#summary-1"><i class="fa fa-check"></i><b>2.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="an-alternative-to-p-values.html"><a href="an-alternative-to-p-values.html"><i class="fa fa-check"></i><b>3</b> An alternative to <em>p</em> values</a>
<ul>
<li class="chapter" data-level="3.1" data-path="an-alternative-to-p-values.html"><a href="an-alternative-to-p-values.html#doing-inference-with-likelihoods"><i class="fa fa-check"></i><b>3.1</b> Doing inference with likelihoods</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="an-alternative-to-p-values.html"><a href="an-alternative-to-p-values.html#a-brief-detour-back-to-sampling-rules"><i class="fa fa-check"></i><b>3.1.1</b> A brief detour back to sampling rules</a></li>
<li class="chapter" data-level="3.1.2" data-path="an-alternative-to-p-values.html"><a href="an-alternative-to-p-values.html#the-likelihood-ratio"><i class="fa fa-check"></i><b>3.1.2</b> The likelihood ratio</a></li>
<li class="chapter" data-level="3.1.3" data-path="an-alternative-to-p-values.html"><a href="an-alternative-to-p-values.html#a-note-about-likelihood-functions-and-probability-distributions"><i class="fa fa-check"></i><b>3.1.3</b> A note about likelihood functions and probability distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="an-alternative-to-p-values.html"><a href="an-alternative-to-p-values.html#testing-more-complex-hypotheses"><i class="fa fa-check"></i><b>3.2</b> Testing more complex hypotheses</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="an-alternative-to-p-values.html"><a href="an-alternative-to-p-values.html#theres-more-than-one-way-to-average"><i class="fa fa-check"></i><b>3.2.1</b> There’s more than one way to average</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="the-bayes-factor.html"><a href="the-bayes-factor.html"><i class="fa fa-check"></i><b>4</b> The Bayes factor</a>
<ul>
<li class="chapter" data-level="4.1" data-path="the-bayes-factor.html"><a href="the-bayes-factor.html#computing-bayes-factors-with-bayesplay"><i class="fa fa-check"></i><b>4.1</b> Computing Bayes factors with <code>bayesplay</code></a></li>
<li class="chapter" data-level="4.2" data-path="the-bayes-factor.html"><a href="the-bayes-factor.html#computing-bayes-factors-with-bayesplay-web"><i class="fa fa-check"></i><b>4.2</b> Computing Bayes factors with Bayesplay-Web</a></li>
<li class="chapter" data-level="4.3" data-path="the-bayes-factor.html"><a href="the-bayes-factor.html#moving-beyond-coin-flips"><i class="fa fa-check"></i><b>4.3</b> Moving beyond coin flips</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="./">Lincoln Colling</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayes rule</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="an-alternative-to-p-values" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> An alternative to <em>p</em> values</h1>
<p>Coming up with an alternative to <em>p</em> values requires us to rearrange our
thinking a bit. So let’s first get straight what we’re doing with frequentist
inference. In frequentist inference we set some parameter to a certain value
(<span class="math inline">\(\theta\)</span>), we then generate data from imaginary experiments using that
parameter setting, and we then compare our data to the data from those
experiments. We then ask the question: “Given that parameter value, how
surprising is our data?” At no point are we making inferences <em>about the value</em>
of <span class="math inline">\(\theta\)</span>. We <strong>set</strong> the value, and we ask a question about our data in
relation to <strong>all the possible data</strong> that might be generated.</p>
<p>To think about what an alternative might look like, let us think back to our
earlier example on the different meanings of probability. With <em>p</em>-values we
thought about probability in terms of relative frequency. We were asking “how
often?” questions. But I also mentioned another example. The example of being
90% sure that the accused committed a crime. If we want to be rational humans,
when we make claims like this what we usually do is examine the evidence. We
<strong>compare</strong> whether there is more evidence for the accused’s guilt or the
accused’s innocence. That is, we take the courtroom evidence and examine
whether it supports hypothesis 1 (the accused is guilty) or hypothesis 2 (the
accused is innocent). To do this we balance of probabilities. Is is more
probable that we’d see this evidence if hypothesis 1 was true, or is it more
probable that we’d see this evidence if hypothesis 2 was true? (In a civil
trial we’d just weigh up the probabilities, but in a criminal trial we’d have
to also examine whether this difference in probabilities exceeds some
threshold. We’ll leave this issue of thresholds for now). Might we be able to
apply the same kind of thinking to statistical evidence?</p>
<p>To understand the concept of statistical evidence, let’s go back to our coin
flipping example. In our coin flipping example, we collected 10 flips and found
8 heads and 2 tails. Our frequentist analysis asked something like, “is this
data surprising?”. But we could ask another question. That question might go
something like this: “Is it more likely that the <strong>bias is 0.6</strong> or that the
<strong>bias is 0.8</strong> given that we’d obtained 8 heads in 10 flips?”</p>
<p>To try and answer this question, we’ll again create some simulations. We’ll
start by creating two <strong>sampling distributions</strong>. For now we’ll keep things
simple and we’ll create these sampling distributions on the assumption that I
intended to flip the coin 10 times. To create our sampling distributions we’ll
first set <span class="math inline">\(\theta\)</span> to 0.6 and run the simulations, and then we’ll set <span class="math inline">\(\theta\)</span>
to 0.8 and run the simulations. I know the distribution they’ll follow, so I’ll
just compute the distributions directly rather than actually running the
simulations.</p>
<p>We can draw the distributions of the possible data that would occur for
different values of P(heads) = <span class="math inline">\(\theta\)</span>. In each of the plots, our
actual observation will be highlighted. Although we’re “simulating” all
possible observations, you’ll see that we’re only going to care about our
<strong>actual</strong> observation. We will want to know the relative frequency with which
<strong>that</strong> result occurs, not the frequency of results that didn’t but might’ve
occurred. I’m going to draw several distributions not just two that correspond
to the values of <span class="math inline">\(\theta\)</span> that we’re interested in.</p>
<p><img src="03-likelihoods_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Let’s take these plots and create a new one out of them. Since we’re just
interested in <strong>our specific observation</strong> we’ll take all the marked points and
put them on a plot of their own. Now we’ll still have relative frequency on the
y-axis, but on the x-axis we won’t have the observation anymore (because we’re
only focused on one specific outcome). Instead, we’ll have <span class="math inline">\(\theta\)</span> on the
x-axis.</p>
<p><img src="03-likelihoods_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>This new plot that we’re created illustrates what’s know as the <strong>likelihood</strong>
function. The likelihood function describes the relationship between values of
the parameter and <strong>our data</strong>. It’s made up of slices of the sampling
distribution-the slices that correspond to our actual observation. Remember
that when we were doing inference with the sampling distribution we were
looking at the extreme tails of the sampling distribution. That is, we were
interested in the entire shape of the sampling distribution. Now we’re instead
only interested in the thin slice that corresponds to our observation.</p>
<div id="doing-inference-with-likelihoods" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Doing inference with likelihoods</h2>
<p>The likelihood plays a key role in Bayesian inference. Inferences on the basis
of likelihoods are derived from what is known at the <em>law of likelihood</em>.
Simply stated, the <em>law of likelihood</em> says that for a given pair of
hypotheses—for example, <span class="math inline">\(\mathcal{H}_1\)</span> that the coin bias is P(heads)=0.6
and <span class="math inline">\(\mathcal{H}_2\)</span> that the coin bias is P(heads)=0.8—then data support
<span class="math inline">\(\mathcal{H}_1\)</span> over <span class="math inline">\(\mathcal{H}_2\)</span> if the likelihood of <span class="math inline">\(\mathcal{H}_1\)</span>
exceeds that of <span class="math inline">\(\mathcal{H}_2\)</span>. Or, put another way, if our data would be
produced more often if <span class="math inline">\(\mathcal{H}_1\)</span> were true than if <span class="math inline">\(\mathcal{H}_2\)</span> were
true, then the data provide support for <span class="math inline">\(\mathcal{H}_1\)</span> over <span class="math inline">\(\mathcal{H}_2\)</span>
(See <a href="https://www.google.co.uk/books/edition/Logic_of_Statistical_Inference/cEJfDAAAQBAJ?hl=en&amp;gbpv=0">Hacking,
1965</a> Chapter 5, for both formulations).</p>
<p>This definition might seem a little opaque, but we can read these likelihood
values straight off our likelihood plot. The height of the likelihood plot, at
each value of <span class="math inline">\(\theta\)</span>, tells you the probability of obtaining your data given
that value of <span class="math inline">\(\theta\)</span>. If the likelihood function is higher at <span class="math inline">\(\theta=0.8\)</span>
than <span class="math inline">\(\theta=0.6\)</span> then the probability of obtaining our data would be higher if
<span class="math inline">\(\theta\)</span> was 0.8 than it would be if <span class="math inline">\(\theta\)</span> was 0.6. Consequently, our data
support the hypothesis that <span class="math inline">\(\theta=0.8\)</span> <em>over</em> the hypothesis <span class="math inline">\(\theta=0.6\)</span>. A
key point here, that’s worth stressing, is that this is a comparison between
two specific hypothesis. Does this data support this one specific hypothesis
over this other specific hypothesis. What you’re doing here is <em>weighing up
probabilities</em> just like you would do in a courtroom.</p>
<div id="a-brief-detour-back-to-sampling-rules" class="section level3" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> A brief detour back to sampling rules</h3>
<p>Before we continue, let’s just go back to something from the previous section.
I made a big deal about how our sampling rules change the shape of the sampling
distribution, and that this then changes the inferences that we make. This is
the case even if nothing changes about our actual data. But do different
sampling rules change the likelihood? To test this out, we’ll generate a new
set of sampling distributions using the other sampling rule (sampling until we
get 2 heads). And from these sampling distributions we’ll generate some
likelihoods.</p>
<p><img src="03-likelihoods_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>We can see that these sampling distributions look very different to the
sampling distributions that we generated above. But what we’re interested in
are just the highlighted points, because we’ll use these to generate our
likelihood.</p>
<p><img src="03-likelihoods_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>The new likelihood might, at first glance, look different to the one we
generated earlier, but it’s just a scaled version of the earlier likelihood. We
can check this just by rescaling the two likelihoods so that they both have a
max of 1.</p>
<p><img src="03-likelihoods_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Now that they’re been rescaled we can see that they’re they same. Note that
scaling changes the absolute distance between points on the likelihood, but it
doesn’t change the <em>relative</em> distance between the points. When we want to know
the difference between two likelihood values we take the <em>ratio</em> of these two
values. The ratio gives us the <em>relative distance</em> between the heights on the
likelihood function, and the <em>relative distance</em> doesn’t change with scaling.</p>
<p>More importantly, however, what this demonstrates is that when we do inference
with <strong>likelihoods</strong> instead of <strong>sampling distributions</strong>, things like
stopping rules, data that wasn’t collected but might have been collected, and
all those other sorts of things that were tricky about <em>p</em>-values don’t come in
to play. We only have the worry about <strong>the data we actually have</strong>, and the
<strong>likelihood</strong> which relates <strong>parameter values</strong> to <strong>data</strong>.</p>
</div>
<div id="the-likelihood-ratio" class="section level3" number="3.1.2">
<h3><span class="header-section-number">3.1.2</span> The likelihood ratio</h3>
<p>The likelihood ratio is going to be our measure of evidence of how much
the data supports one hypothesis over another. If the likelihood at point
one (<span class="math inline">\(\theta_1\)</span>) is four times the larger than the likelihood at point two
(<span class="math inline">\(\theta_2\)</span>) then the data are four times more likely under the hypothesis
<span class="math inline">\(\theta = \theta_1\)</span> than the hypothesis <span class="math inline">\(\theta = \theta_2\)</span>. Or simply
put, the data supports the hypothesis <span class="math inline">\(\theta=\theta_1\)</span> over
<span class="math inline">\(\theta=\theta_2\)</span> but a factor of 4 to 1.</p>
<p>Let’s look at the likelihood for our actual data and our two hypotheses
about the coin bias. Just to drive home the point that the sampling rule
doesn’t matter, I’m going to work out the likelihood ratio for the
sampling rule where I flip the coin 10 times and the sampling rule where
I flip the coin until I get 2 heads and just happen to flip it 10 times.
We’ll see that the absolute values of the likelihoods change (as we saw in
the plots above), but that the likelihood ratio between the hypotheses
don’t change.</p>
<p>To make sure that the numbers work out correctly, I won’t use simulations
to generate the likelihoods. Instead I’ll just generate each likelihood
with the relevant formula.</p>
<p>First, for version 1, where I flip the coin 10 times (<strong>binomial</strong>
sampling rule).</p>
<p>The likelihood for <span class="math inline">\(\mathcal{H}_1\)</span> (P(heads) = 0.6) is 0.12</p>
<p>The likelihood for <span class="math inline">\(\mathcal{H}_2\)</span> (P(heads) = 0.8) is 0.3</p>
<p>The likelihood ratio is 0.4</p>
<p>The data are 0.4 times more probable under <span class="math inline">\(\mathcal{H}_1\)</span> than <span class="math inline">\(\mathcal{H}_2\)</span></p>
<p>Second, for version 2, where I flip the coin until I get 2 hears
(<strong>negative-binomial</strong> sampling rule).</p>
<p>The likelihood for <span class="math inline">\(\mathcal{H}_1\)</span> (P(heads) = 0.6) is 0.1</p>
<p>The likelihood for <span class="math inline">\(\mathcal{H}_2\)</span> (P(heads) = 0.8) is 0.24</p>
<p>The likelihood ratio is 0.4</p>
<p>The data are 0.4 times more probable under <span class="math inline">\(\mathcal{H}_1\)</span> than <span class="math inline">\(\mathcal{H}_2\)</span></p>
</div>
<div id="a-note-about-likelihood-functions-and-probability-distributions" class="section level3" number="3.1.3">
<h3><span class="header-section-number">3.1.3</span> A note about likelihood functions and probability distributions</h3>
<p>One common misconception about likelihood functions is that they’re
probability distributions. This misconception can come in a few different
forms, so it’s worth just stressing again what a likelihood function is.</p>
<p>First, we can tell a likelihood function isn’t a probability distribution,
because for a probability distribution the area under the curve would have
to sum to 1. Each point on a probability distribution gives the probability
of a specific event. The whole curve describes all the events that could
happen, and the area under the curve gives the probability that one of the
possible events happens. That is, it is the sum of all the individual
probabilities of the different events.</p>
<p>In the plot below, we can see the likelihood functions for different
events (different numbers of heads in 10 flips). We can see that the area
under the curve varies in each case. If these were probability
distributions then the area under the curve in each case would be 1.</p>
<p><img src="03-likelihoods_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>This misconception about likelihood functions being probability
distribution often takes the form of thinking that the likelihood function
tells use the probability of the parameter being a specific value. That
is, it tells us that there’s a higher probability that <span class="math inline">\(\theta=\theta_1\)</span>
than <span class="math inline">\(\theta=\theta_2\)</span>, given our data. Put another way, this
misconception states that the likelihood tells us <span class="math inline">\(p(\theta|y)\)</span>. This
quantity, however, is what’s know as the <strong>posterior probability</strong>.
Rather, the likelihood tells us the reserve conditional, or <span class="math inline">\(p(y|\theta)\)</span>.
That is, it tells use the probability of obtaining our data given
different values of the parameter.</p>
<p>To emphasise that the likelihood is not a probability distribution it is
often denoted <span class="math inline">\(\mathcal{L}(\theta|y)\)</span>.</p>
</div>
</div>
<div id="testing-more-complex-hypotheses" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Testing more complex hypotheses</h2>
<p>So we’ve seen that comparing likelihoods (by taking their ratio) can tell
us which hypothesis is better supported by the data. However, there’s
a couple of problems with what we’ve done up until now. First, how do we
know explicitly set a threshold for when we would start digging for
treasure. Is there also a threshold for likelihood ratios? To answer this
question, we’re going to have to take into account a lot of additional
factors. And the answer to this question is probably going to be
context-dependent. For example, if we’re placing bets on hypotheses, we’re
probably going to want to take into account the relative pay-offs. If
we’re using evidence to decide somebody’s guilt in a court case, we’re
probably going to want to take into account things like “reasonable
doubt”. In short, there’s not a straight forward answer to this question,
so we’ll set it aside for now. Instead, we’ll turn to the second problem.</p>
<p>The second problem with what we’ve done up until now is that we’ve just
been comparing single point hypothesis. We can can say, for example,
whether the data supports P(heads) = 0.5 over the hypothesis P(heads)
= 0.8, and we can quantify this level of support. But usually, we are not
comparing two simple hypotheses like this. Our hypotheses take a more
complex form like: “Is the coin fair?”</p>
<p>How might we go about answering this question?</p>
<p>To come up with a way to answer this question we’re going to think about
hypotheses in terms of <strong>predictions</strong>. Our first hypothesis,
<span class="math inline">\(\mathcal{H}_0\)</span>, will be that the coin is fair. And we’ll say a fair coin
has a bias of 0.5. What do we predict will happen if we flip the coins 10
times? Most of the time it’ll show around about 5 heads and 5 tails, but
it will also rarely show 1 head and 9 heads etc. If we plotted it, it
would just be our sampling distribution from before.</p>
<p>For <span class="math inline">\(\mathcal{H}_1\)</span>, that the coin isn’t fair, what do we predict will
happen if we flipped it 10 times? Before we can work this out we need to
think a little bit about what it means for a coin not to be fair. For now,
let’s say that it means that it can have some bias between 0 and 1, but
that we don’t know what it is. For our fair coin, if we collected a very
large number of samples the most common outcome would be 5 heads and
5 tails, but would be the most common outcome with our unfair coin? Would
it be 5 heads and 5 tails? Would it be 0 heads? 1 head? 9 heads? Do we
have any grounds for <strong>predicting</strong> that one outcome would be more common
than another outcome? We arguably do not. If so, then if I asked which of
the 11 possible outcomes (from a sample of 10 coin flips) is more probable
than the others you might say none. If none of the outcomes are more
probable than any of the other outcomes, and given that there’s 11
possible outcomes, then our prediction must be that each outcome has
a 1 in 11 chance of occurring.</p>
<p>Below, we can see plots of our two predictions. First, what we would
predict if we knew the coin bias was 0.5, and second what we would predict
if we had no reason for favouring one outcome over another.</p>
<p><img src="03-likelihoods_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Now that we have a intuition for hypotheses in terms of predictions, let
use formalise it a bit. And instead of thinking about all the data that
might be produced let’s just try and think about the probability of
obtaining our data of 8 heads in 10 flips. If a coin is fair, then in 10
coin flips there are exactly <span class="math inline">\(2^{10}\)</span> possible sequences and 45 of these
sequences would give 8 heads in 10 flips. Therefore, if the coin is fair,
then the probability of obtaining our result of 8 heads in 10 flips in
<span class="math inline">\(\frac{45}{1024}\)</span>, or about 0.044. I’ve worked this out exactly, but we’d
get the same value if we ran the simulations, or if we just looked at the
likelihood function at <span class="math inline">\(\theta=0.5\)</span>. This is after all, what the
likelihood function tells use: the probability of obtaining our data for
a given value of the parameter.</p>
<p>Now on to the more complex example where the coin bias is some unknown
value between 0 and 1. What now is the probability of obtaining our data.
One good strategy of dealing with unknowns is to average across the
possibilities. For example, if I didn’t know what the coin bias was, but
I knew it could either be 0.5 or 0.6, then to work out the probability of
obtaining our current data I could just work out the probability of
obtaining our current data if the bias was 0.5 (~0.044), and then work out
the probability of obtaining our current data if 0.6 (~0.121), and then
just average them together (~0.082). Again, I just take the values from
the likelihood function at <span class="math inline">\(\theta=0.5\)</span> and <span class="math inline">\(\theta=0.6\)</span> and aveage them
together.</p>
<p>But in our example it’s not just the case that the bias of the coin could
be 0.5 or 0.6. For our second hypothesis we said it could be any value
between 0 and 1. That is, hypothesis is the set <span class="math inline">\(\Theta = \{\theta_1,\theta_2,...,\theta_n\}\)</span> where each <span class="math inline">\(\theta_1\)</span> to <span class="math inline">\(\theta_n\)</span>
is some value between 0 and 1. To keep things simple for now, we’ll say
that <span class="math inline">\(\Theta =\{\theta_1=\frac{0}{10}, \theta_2=\frac{1}{10},...,\theta_{11}=\frac{10}{10}\}\)</span>. An average is just
a sum where each value is multiplied by <span class="math inline">\(\frac{1}{n}\)</span>, therefore, the
average across these 11 values would be:</p>
<p><span class="math display">\[\sum_{i=1}^{11}\mathcal{L}(\theta_i|\mathbf{y})\cdot{}\frac{1}{11}\]</span></p>
<p>This gives a value of approximately <span class="math inline">\(\frac{1}{12}\)</span>, which is pretty close
to the value of <span class="math inline">\(\frac{1}{11}\)</span> we worked out earlier. Why is it not the
same? Well, earlier, we said it could be <strong>any</strong> value between 0 and 1.
We’re only looking at 11 values. Let’s instead look at 101 values between
0 and 1. Now <span class="math inline">\(\Theta = \{\theta_1=\frac{0}{100}, \theta_2=\frac{1}{100},...,\theta_{101}=\frac{100}{100}\}\)</span>. Now we get
a value that’s even closer to <span class="math inline">\(\frac{1}{11}\)</span>. To get to exactly
<span class="math inline">\(\frac{1}{11}\)</span>, however, we’re going to have to look at even more points.
Instead of spacing the points out by <span class="math inline">\(\frac{1}{10}\)</span> or <span class="math inline">\(\frac{1}{100}\)</span>,
we’re going to need infinitesimally small spacing. That’s means we just
switch out the sum for an integral, but the logic is the same. We’re still
just taking an average.</p>
<p><span class="math display">\[\int_{\theta\in\Theta}\mathcal{L}(\theta|\mathbf{y})d(\theta)\]</span></p>
<p>Now that we’re taking an integral, we get exactly <span class="math inline">\(\frac{1}{11}\)</span>.</p>
<p>Now that we have these two values: First, <span class="math inline">\(\frac{45}{1024}\)</span>, which gives the
probability of obtaining 8 heads in 10 flips if <span class="math inline">\(\theta=0.5\)</span>, and second,
<span class="math inline">\(\frac{1}{11}\)</span>, which the probability of obtaining 8 head in flips if <span class="math inline">\(\theta\)</span>
was some unknown value between 0 and 1, what can we do with them? Well, we can
just take the ratio! Just like we did with the two simple point hypotheses, we
can also take the ratio between our simple point hypothesis and our more
complex hypothesis. Taking this ratio tells us that’s we’d be <span class="math inline">\(2\frac{34}{495}\)</span>
times more likely to see our data if <span class="math inline">\(\theta\)</span> was some unknown value between 0
and 1 than if <span class="math inline">\(\theta=0.5\)</span>.</p>
<p>Thinking back to the <em>law of likelihood</em> that we covered at the start of
this section, we said if our data would be produced more often if
<span class="math inline">\(\mathcal{H}_1\)</span> were true than if <span class="math inline">\(\mathcal{H}_2\)</span> were true, then the data
provide support for <span class="math inline">\(\mathcal{H}_1\)</span> over <span class="math inline">\(\mathcal{H}_2\)</span>. This is exactly
the number that we’ve just worked out.</p>
<div id="theres-more-than-one-way-to-average" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> There’s more than one way to average</h3>
<p>Above we worked out two values. The second number we calculated by
averaging the likelihood function, but the first number we calculated by
just taking a single point on the likelihood function. So one involved an
average and the other did not. Or did it? We can actually think of both as
involving an average of the likelihood function. They’re just different
kinds of average. We can view both as taking a <em>weighted average</em>, where
different values contribute more or less to the average. For the second
number, all values in the average were <em>weighted equally</em>. That is, it was
just like a regular average. For the first, it can be viewed as taking an
average where the likelihood value for <span class="math inline">\(\theta=0.5\)</span> is given a weight of
1, and all over values of given a weight of 0. We could visualise these
weighting in the plots below.</p>
<p><img src="03-likelihoods_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>These <em>weightings</em> can be thought of as <em>probability distributions</em>. We
are going to call these <strong>priors</strong>. Mathematically, they represents the
weights that we apply to the values that we average together. But what do
they represents <em>conceptually</em>. One way to think of them is that they
<em>represent our beliefs about the parameter value</em> (in this case the <em>coin
bias</em>). Or, that they represent our <em>model of the hypothesis</em>-that is,
they represent what the hypothesis has to say about the parameter value.
So the fair coin hypothesis represents is a model that says <em>the coin bias
is exactly 0.5</em>. The other hypothesis is a model that say <em>all values of
the coin bias between 0 and 1 are equally probable</em>.</p>
<p>At the start of this section we said that for our alternative for a fair
coin we’d say that all values of the coin bias were equally likely, and
this is what we’d mean by an unfair coin. But this is only one possible
model of an unfair coin. We might actually think that if a coin is unfair
then it’ll show heads far more often than tails. Or, we might think that
unfair coins will show tails more often than heads. We might even think
that unfair coins will behave very similarly to fair coins, but they’ll
just outcomes of 5 head and 5 tails a little bit less often than the
<span class="math inline">\(\frac{252}{1024}\)</span> that we’d see with a perfectly fair coin. These are all
different <em>models</em> that we might have about unfair coins. We can represent
these hypotheses in terms of what they say about the coin bias parameter.
That is, we can represent them as <em>weights</em> or <em>priors</em>. We’ll learn more
in the next section about how to specify these, but for now I’ll just
generate some plot.</p>
<p><img src="03-likelihoods_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>In panel <strong>A</strong>, values of the coin bias closer to 1 (show heads all the time)
and given more weight than values closer to 0 (never show heads). This means we
except the coin to show heads more often. In panel <strong>B</strong>, we see the opposite.
Finally, in panel <strong>C</strong>, we weight values closer to 0.5 (fair) higher than
values closer to 0 or 1. That is, we don’t think the coin bias is exactly 0.5,
but we think values closer to 0.5 are more probable than values further away
from 0.5.</p>
<p>Now that we’re taking a weighted average, our earlier formula before:</p>
<p><span class="math display">\[\int_{\theta\in\Theta}\mathcal{L}(\theta|\mathbf{y})d(\theta)\]</span></p>
<p>Now just becomes:</p>
<p><span class="math display">\[\int_{\theta\in\Theta}\mathcal{L}(\theta|\mathbf{y})p(\theta)d\theta\]</span></p>
<p>In words we’d read this as:</p>
<blockquote>
<p><em>The probability of obtaining our data under the specified model is equal to
the integral of the likelhood (the model of the data) multiplied by the prior
(the weights).</em></p>
</blockquote>
<p>We might denote this as <span class="math inline">\(p(Y|\mathcal{M}_i\)</span>) or simply <span class="math inline">\(\mathcal{M}_i\)</span>. When
comparing two models—for example, <span class="math inline">\(\mathcal{M}_1\)</span> and <span class="math inline">\(\mathcal{M}_0\)</span>, we
take the ratio as follows:</p>
<p><span class="math display">\[\frac{\mathcal{M}_1}{\mathcal{M}_0}\]</span></p>
<p>Try not to be too intimidated by the formula above. It just means that we’re
working out the probability of obtaining our data for a given value of the
parameter, and that we’re doing this for a range of parameter values. And
finally, we’re taking a weighted average of these. There’s only 3 parts to the
formula.</p>
<ol style="list-style-type: decimal">
<li><p>The likelihood, which tells us the probability of obtained our data at
a specific value of the parameter: <span class="math inline">\(\mathcal{L}(\theta|\mathbf{y})\)</span></p></li>
<li><p>The prior, which determines the weights for weighted average of the
likelihood values: <span class="math inline">\(p(\theta)\)</span></p></li>
<li><p>The integral, which performs the “averaging” across all the different values
of the parameter range: <span class="math inline">\(\int_{\theta\in\Theta}...d\theta\)</span></p></li>
</ol>
<div id="visualising-predictions" class="section level4" number="3.2.1.1">
<h4><span class="header-section-number">3.2.1.1</span> Visualising predictions</h4>
<p>We can also represent these different models of the coin bais in terms of what
outcomes we’d predict, just like we did with the earlier predictions. In the
next section, we’ll also learn about how to turns priors into predictions, but
for now we’ll just look at some plots. In each of these plots we’ll show what
we would predict if the coin was exactly fair overlaid on each of these
different models of <em>unfairness</em>. In each of the plots we’ll highlight our
actual outcome of 8 heads in 10 flips.</p>
<p><img src="03-likelihoods_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>In panel <strong>A</strong>, we see the predictions from our fair coin model against our
predictions from a model where the coin shows heads more often. In panel <strong>B</strong>,
we see the fair coin predictions against a coin that shows tails more often. In
panel <strong>C</strong> we see our fair coin model again a model where the bias is just
slightly off from fair. And finally in panel <strong>D</strong>, we see the predictions of
the fair coin model against a model where we have no reason for thinking that
one outcome is more likely than any other outcome.</p>
<p>In each of these panels we can weigh up the evidence for whether our data
support one model over the other by looking at whether our data would be
produced more often if <span class="math inline">\(\mathcal{H}_1\)</span> were true than if <span class="math inline">\(\mathcal{H}_2\)</span> were
true. That is,w we can see whether the data provide support for <span class="math inline">\(\mathcal{H}_1\)</span>
over <span class="math inline">\(\mathcal{H}_2\)</span> just by looking at whether the blue highlighted point is
higher (more probable) than the red highlighted point (less probable).</p>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="criticisms-of-p-values.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="the-bayes-factor.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": [["bayes_notes.pdf", "pdf"]],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
